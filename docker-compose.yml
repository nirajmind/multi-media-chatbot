services:
  # New service for Hugging Face Models
  hf_models_downloader:
    build:
      context: .
      dockerfile: Dockerfile.hf_models # Points to your new Dockerfile
      platforms:
        - linux/amd64 # Ensure compatibility with your architecture
    # This service should run once to download models, then exit or stay alive for cache sharing
    # If it's just for building cache, you don't need ports or restart policies
    volumes:
      # Map a named volume to the cache directory inside the container
      - hf_cache_volume:/app/hf_cache
    # You might run this with 'docker compose run --rm hf_models_downloader' initially
    # or ensure other services depend on it being 'healthy' or 'built'
  chainlit:
    build:
      context: .
      dockerfile: Dockerfile.chainlit
      platforms:
        - linux/amd64 # Ensure compatibility with your architecture
    ports:
      - "8000:8000"
    env_file:
      - .env
    restart: unless-stopped
    volumes: 
      - ./short_term_memory:/app/data
      - hf_cache_volume:/app/hf_cache
    depends_on:
      - hf_models_downloader  
  whatsapp:
    build:
      context: .
      dockerfile: Dockerfile
      platforms:
        - linux/amd64 # Ensure compatibility with your architecture
    ports:
      - "8080:8080"
    env_file:
      - .env
    restart: unless-stopped
    volumes: 
      - ./short_term_memory:/app/data
      - hf_cache_volume:/app/hf_cache
    depends_on:
      - hf_models_downloader

# Define your named volumes (CRITICAL)
volumes:
  hf_cache_volume: # This named volume will persist the downloaded models
    driver: local
  short_term_memory: # This named volume will persist your app data (if not bind mount)
    driver: local      